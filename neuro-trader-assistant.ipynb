{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Трейдерский нейро-помощник"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В данном блокноте реализован трейдерский нейро-помощник на основе большой языковой модели GigaChat3 с функционалом управления сделками через function calls. Система объединяет RAG-архитектуру для работы с базой знаний о сделках трейдера и возможность выполнения действий через вызовы функций.\n",
        "\n",
        "\n",
        "Основная идея данной работы, создать систему, которая будет работать не только как продвинутая вопросно-ответная система, но и решает задачи взаимодействия с помощью естественного языка с операциями на финансовом рынке (этот момент еще дорабатывать, но базовая демонстрация имеется)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вводные данные:**\n",
        "\n",
        "1. Нейро-помощник выполняет роль ассистента для трейдера и управления сделками;\n",
        "2. База знаний представляет из себя хранилище графов, информация извлекается из текстовых файлов со сделками;\n",
        "3. Фреймворк LlamaIndex;\n",
        "4. Модель ai-sage/GigaChat3-10B-A1.8B-bf16 (российская контурная LLM);\n",
        "5. Функционал function calls для открытия и закрытия сделок;\n",
        "6. Модерация через OpenAI API;\n",
        "7. Трассировка запросов и работы модели с помощью Phoenix (Arize Phoenix) для мониторинга и отладки.\n",
        "8. Улучшение качества ответов и снижение уровня галлюцинаций с помощью метода ресортировки контента\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задачи нейро-помощника:**\n",
        "\n",
        "1. Обращаться к базе знаний для получения информации о сделках трейдера.\n",
        "2. Отвечать точно, основываясь только на данных из источника.\n",
        "3. Если информация отсутствует, честно говорить, что ответ неизвестен (удалось добиться частично, но это во многом зависит от самой модели).\n",
        "4. Избегать излишних эмоций, фраз и догадок.\n",
        "5. Понимать запросы пользователя и выполнять действия через function calls:\n",
        "   - Открытие новых сделок\n",
        "   - Закрытие существующих сделок\n",
        "   - Получение статистики по сделкам\n",
        "   - Системная функция, которая предположительно будет доступна только пользователям с расширенными правами при реальной работе\n",
        "   - Возможность расширения и добавления новых функций\n",
        "6. Автоматически добавлять статистику сделок в контекст для более точных ответов.\n",
        "\n",
        "По последнему пункту возможно множество расширений, например, в случае многопользовательской модели, когда модель будут использовать несколько человек в одном сервисе, то в системную информацию можно добавлять дополнительные данные по конкретному пользователю, чтобы улучшить поиск в общей базе знаний для всех трейдеров, либо использовать разделенную логику хранения и поиска, но над этим я пока не особо думал, так что не знаю как будет лучше.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Подготовка\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Установка всех зависимостей одной командой\n",
        "# !pip install \\\n",
        "#   llama-index-core \\\n",
        "#   \"arize-phoenix[evals,llama-index]\" \\\n",
        "#   gcsfs \\\n",
        "#   nest-asyncio \\\n",
        "#   \"openinference-instrumentation-llama-index>=2.0.0\" \\\n",
        "#   llama-index \\\n",
        "#   ipython \\\n",
        "#   langchain \\\n",
        "#   pypdf \\\n",
        "#   langchain_community \\\n",
        "#   llama-index-llms-huggingface \\\n",
        "#   llama-index-embeddings-huggingface \\\n",
        "#   llama-index-embeddings-langchain \\\n",
        "#   langchain-huggingface \\\n",
        "#   sentencepiece \\\n",
        "#   accelerate \\\n",
        "#   bitsandbytes \\\n",
        "#   peft \\\n",
        "#   llama-index-readers-file \\\n",
        "#   ipykernel \\\n",
        "#   llama-index-postprocessor-colbert-rerank \\\n",
        "#   openai \\\n",
        "#   tf-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Путь к директории с документами\n",
        "source_path = 'data/deals'\n",
        "deals_registry_path = 'data/deals/deals_registry.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "2025-11-30 17:57:47,806 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "if not HF_TOKEN:\n",
        "    # Try to read token from .env file in current or parent directories\n",
        "    from dotenv import load_dotenv, find_dotenv\n",
        "    dotenv_path = find_dotenv()\n",
        "    if dotenv_path:\n",
        "        load_dotenv(dotenv_path)\n",
        "        HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "    if not HF_TOKEN:\n",
        "        raise ValueError(\"HF_TOKEN environment variable is not set, and was also not found in your .env file. Please set it in your .env file or export it.\")\n",
        "\n",
        "login(HF_TOKEN, add_to_git_credential=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка модели GigaChat3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core import KnowledgeGraphIndex\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.graph_stores import SimpleGraphStore\n",
        "from llama_index.core import StorageContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, BitsAndBytesConfig\n",
        "import torch\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core.postprocessor import LongContextReorder\n",
        "import getpass\n",
        "import os\n",
        "from datetime import datetime\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Все работы производил на собственной машине, для запуска в коллабе будет необходима расширенная, платная версия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "CUDA version: 12.4\n",
            "GPU count: 1\n",
            "GPU name: NVIDIA GeForce RTX 3090\n",
            "GPU memory: 24.00 GB\n"
          ]
        }
      ],
      "source": [
        "# Проверка доступности GPU\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    print(\"WARNING: CUDA not available, using CPU\")\n",
        "    device = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Использовать я решил российскую контурную модель... Ну как российскую, она так или иначе основана на архитектуре DeepSeek, который в свою очередь является продуктом дистилляции моделей таких компаний как OpenAI, Яндекса и других.\n",
        "\n",
        "Когда я выбирал модель, я забыл, что возможность вызова функций (funtions call) большими языковыми моделями является как дополнительный параметр, а мне, по всей видимости попалась модель без данной вохможности, хотя в самой архитектуре deepseek, исходя из документации, есть такая возможность, но чтобы я ни делал, как бы я ни старался, мне не удалось заставить сгенерировать модель специальные токены во время вызовов функций вроде:\n",
        "\n",
        "```\n",
        "<TOOL>\n",
        "name_of_functiions\n",
        "</TOOL>\n",
        "```\n",
        "\n",
        "Что-то подобное удалось добиться за счет хорошего следования инструкциям, я напрямую написал в системную информацию о наличии функций и как их вызывать и модель, следуя инстуркциям, может их вызывать, а уже мой обработчик ответов, который я внедрил между ответами модели и запросами пользователя, сможет определенным образом на это реагировать. Костыль, я знаю, но я провозился с простым запуском данной модели несколько дней на своей видеокарте, попутно решая проблемы загрузки весов, совместимости библиотек и прочих ошибок. Я использовал до этого модель от Т-Банка, которая на архитектуре Qwen'а, она совершенно точно способна вызвать функции, но я не стал тратить еще неделю, чтобы поменять модель, так как сроки и дедлайн не дадут мне закончить данную работу вовремя.\n",
        "\n",
        "Мои попытки я все равно решил оставить в коде, где происходит описание функций для параметра tools или tool, так как я использую спец библиотеку для поиска RAG, то я искал в документации по ней как заставить модель вызывать функции и при этом быть способной искать инфу в базе знаний, но что-то особо ничего не получилось, не знаю в чем причина.\n",
        "\n",
        "Также пробовал описывать функции для вызова по формату OpenAI, чтобы их потом передать в саму модель, но также не получилось."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Используем модель GigaChat3\n",
        "model_name = \"ai-sage/GigaChat3-10B-A1.8B-bf16\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Настраиваем токенизатор, чтобы не возвращать token_type_ids\n",
        "# Это необходимо для избежания ошибок с моделями, которые не поддерживают этот параметр\n",
        "if hasattr(tokenizer, 'return_token_type_ids'):\n",
        "    tokenizer.return_token_type_ids = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-30 17:57:50,710 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6bd9339ddeb45c59139fae33006b7ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ai-sage/GigaChat3-10B-A1.8B-bf16 were not used when initializing DeepseekV3ForCausalLM: ['model.layers.26.eh_proj.weight', 'model.layers.26.embed_tokens.weight', 'model.layers.26.enorm.weight', 'model.layers.26.hnorm.weight', 'model.layers.26.input_layernorm.weight', 'model.layers.26.mlp.experts.0.down_proj.weight', 'model.layers.26.mlp.experts.0.gate_proj.weight', 'model.layers.26.mlp.experts.0.up_proj.weight', 'model.layers.26.mlp.experts.1.down_proj.weight', 'model.layers.26.mlp.experts.1.gate_proj.weight', 'model.layers.26.mlp.experts.1.up_proj.weight', 'model.layers.26.mlp.experts.10.down_proj.weight', 'model.layers.26.mlp.experts.10.gate_proj.weight', 'model.layers.26.mlp.experts.10.up_proj.weight', 'model.layers.26.mlp.experts.11.down_proj.weight', 'model.layers.26.mlp.experts.11.gate_proj.weight', 'model.layers.26.mlp.experts.11.up_proj.weight', 'model.layers.26.mlp.experts.12.down_proj.weight', 'model.layers.26.mlp.experts.12.gate_proj.weight', 'model.layers.26.mlp.experts.12.up_proj.weight', 'model.layers.26.mlp.experts.13.down_proj.weight', 'model.layers.26.mlp.experts.13.gate_proj.weight', 'model.layers.26.mlp.experts.13.up_proj.weight', 'model.layers.26.mlp.experts.14.down_proj.weight', 'model.layers.26.mlp.experts.14.gate_proj.weight', 'model.layers.26.mlp.experts.14.up_proj.weight', 'model.layers.26.mlp.experts.15.down_proj.weight', 'model.layers.26.mlp.experts.15.gate_proj.weight', 'model.layers.26.mlp.experts.15.up_proj.weight', 'model.layers.26.mlp.experts.16.down_proj.weight', 'model.layers.26.mlp.experts.16.gate_proj.weight', 'model.layers.26.mlp.experts.16.up_proj.weight', 'model.layers.26.mlp.experts.17.down_proj.weight', 'model.layers.26.mlp.experts.17.gate_proj.weight', 'model.layers.26.mlp.experts.17.up_proj.weight', 'model.layers.26.mlp.experts.18.down_proj.weight', 'model.layers.26.mlp.experts.18.gate_proj.weight', 'model.layers.26.mlp.experts.18.up_proj.weight', 'model.layers.26.mlp.experts.19.down_proj.weight', 'model.layers.26.mlp.experts.19.gate_proj.weight', 'model.layers.26.mlp.experts.19.up_proj.weight', 'model.layers.26.mlp.experts.2.down_proj.weight', 'model.layers.26.mlp.experts.2.gate_proj.weight', 'model.layers.26.mlp.experts.2.up_proj.weight', 'model.layers.26.mlp.experts.20.down_proj.weight', 'model.layers.26.mlp.experts.20.gate_proj.weight', 'model.layers.26.mlp.experts.20.up_proj.weight', 'model.layers.26.mlp.experts.21.down_proj.weight', 'model.layers.26.mlp.experts.21.gate_proj.weight', 'model.layers.26.mlp.experts.21.up_proj.weight', 'model.layers.26.mlp.experts.22.down_proj.weight', 'model.layers.26.mlp.experts.22.gate_proj.weight', 'model.layers.26.mlp.experts.22.up_proj.weight', 'model.layers.26.mlp.experts.23.down_proj.weight', 'model.layers.26.mlp.experts.23.gate_proj.weight', 'model.layers.26.mlp.experts.23.up_proj.weight', 'model.layers.26.mlp.experts.24.down_proj.weight', 'model.layers.26.mlp.experts.24.gate_proj.weight', 'model.layers.26.mlp.experts.24.up_proj.weight', 'model.layers.26.mlp.experts.25.down_proj.weight', 'model.layers.26.mlp.experts.25.gate_proj.weight', 'model.layers.26.mlp.experts.25.up_proj.weight', 'model.layers.26.mlp.experts.26.down_proj.weight', 'model.layers.26.mlp.experts.26.gate_proj.weight', 'model.layers.26.mlp.experts.26.up_proj.weight', 'model.layers.26.mlp.experts.27.down_proj.weight', 'model.layers.26.mlp.experts.27.gate_proj.weight', 'model.layers.26.mlp.experts.27.up_proj.weight', 'model.layers.26.mlp.experts.28.down_proj.weight', 'model.layers.26.mlp.experts.28.gate_proj.weight', 'model.layers.26.mlp.experts.28.up_proj.weight', 'model.layers.26.mlp.experts.29.down_proj.weight', 'model.layers.26.mlp.experts.29.gate_proj.weight', 'model.layers.26.mlp.experts.29.up_proj.weight', 'model.layers.26.mlp.experts.3.down_proj.weight', 'model.layers.26.mlp.experts.3.gate_proj.weight', 'model.layers.26.mlp.experts.3.up_proj.weight', 'model.layers.26.mlp.experts.30.down_proj.weight', 'model.layers.26.mlp.experts.30.gate_proj.weight', 'model.layers.26.mlp.experts.30.up_proj.weight', 'model.layers.26.mlp.experts.31.down_proj.weight', 'model.layers.26.mlp.experts.31.gate_proj.weight', 'model.layers.26.mlp.experts.31.up_proj.weight', 'model.layers.26.mlp.experts.32.down_proj.weight', 'model.layers.26.mlp.experts.32.gate_proj.weight', 'model.layers.26.mlp.experts.32.up_proj.weight', 'model.layers.26.mlp.experts.33.down_proj.weight', 'model.layers.26.mlp.experts.33.gate_proj.weight', 'model.layers.26.mlp.experts.33.up_proj.weight', 'model.layers.26.mlp.experts.34.down_proj.weight', 'model.layers.26.mlp.experts.34.gate_proj.weight', 'model.layers.26.mlp.experts.34.up_proj.weight', 'model.layers.26.mlp.experts.35.down_proj.weight', 'model.layers.26.mlp.experts.35.gate_proj.weight', 'model.layers.26.mlp.experts.35.up_proj.weight', 'model.layers.26.mlp.experts.36.down_proj.weight', 'model.layers.26.mlp.experts.36.gate_proj.weight', 'model.layers.26.mlp.experts.36.up_proj.weight', 'model.layers.26.mlp.experts.37.down_proj.weight', 'model.layers.26.mlp.experts.37.gate_proj.weight', 'model.layers.26.mlp.experts.37.up_proj.weight', 'model.layers.26.mlp.experts.38.down_proj.weight', 'model.layers.26.mlp.experts.38.gate_proj.weight', 'model.layers.26.mlp.experts.38.up_proj.weight', 'model.layers.26.mlp.experts.39.down_proj.weight', 'model.layers.26.mlp.experts.39.gate_proj.weight', 'model.layers.26.mlp.experts.39.up_proj.weight', 'model.layers.26.mlp.experts.4.down_proj.weight', 'model.layers.26.mlp.experts.4.gate_proj.weight', 'model.layers.26.mlp.experts.4.up_proj.weight', 'model.layers.26.mlp.experts.40.down_proj.weight', 'model.layers.26.mlp.experts.40.gate_proj.weight', 'model.layers.26.mlp.experts.40.up_proj.weight', 'model.layers.26.mlp.experts.41.down_proj.weight', 'model.layers.26.mlp.experts.41.gate_proj.weight', 'model.layers.26.mlp.experts.41.up_proj.weight', 'model.layers.26.mlp.experts.42.down_proj.weight', 'model.layers.26.mlp.experts.42.gate_proj.weight', 'model.layers.26.mlp.experts.42.up_proj.weight', 'model.layers.26.mlp.experts.43.down_proj.weight', 'model.layers.26.mlp.experts.43.gate_proj.weight', 'model.layers.26.mlp.experts.43.up_proj.weight', 'model.layers.26.mlp.experts.44.down_proj.weight', 'model.layers.26.mlp.experts.44.gate_proj.weight', 'model.layers.26.mlp.experts.44.up_proj.weight', 'model.layers.26.mlp.experts.45.down_proj.weight', 'model.layers.26.mlp.experts.45.gate_proj.weight', 'model.layers.26.mlp.experts.45.up_proj.weight', 'model.layers.26.mlp.experts.46.down_proj.weight', 'model.layers.26.mlp.experts.46.gate_proj.weight', 'model.layers.26.mlp.experts.46.up_proj.weight', 'model.layers.26.mlp.experts.47.down_proj.weight', 'model.layers.26.mlp.experts.47.gate_proj.weight', 'model.layers.26.mlp.experts.47.up_proj.weight', 'model.layers.26.mlp.experts.48.down_proj.weight', 'model.layers.26.mlp.experts.48.gate_proj.weight', 'model.layers.26.mlp.experts.48.up_proj.weight', 'model.layers.26.mlp.experts.49.down_proj.weight', 'model.layers.26.mlp.experts.49.gate_proj.weight', 'model.layers.26.mlp.experts.49.up_proj.weight', 'model.layers.26.mlp.experts.5.down_proj.weight', 'model.layers.26.mlp.experts.5.gate_proj.weight', 'model.layers.26.mlp.experts.5.up_proj.weight', 'model.layers.26.mlp.experts.50.down_proj.weight', 'model.layers.26.mlp.experts.50.gate_proj.weight', 'model.layers.26.mlp.experts.50.up_proj.weight', 'model.layers.26.mlp.experts.51.down_proj.weight', 'model.layers.26.mlp.experts.51.gate_proj.weight', 'model.layers.26.mlp.experts.51.up_proj.weight', 'model.layers.26.mlp.experts.52.down_proj.weight', 'model.layers.26.mlp.experts.52.gate_proj.weight', 'model.layers.26.mlp.experts.52.up_proj.weight', 'model.layers.26.mlp.experts.53.down_proj.weight', 'model.layers.26.mlp.experts.53.gate_proj.weight', 'model.layers.26.mlp.experts.53.up_proj.weight', 'model.layers.26.mlp.experts.54.down_proj.weight', 'model.layers.26.mlp.experts.54.gate_proj.weight', 'model.layers.26.mlp.experts.54.up_proj.weight', 'model.layers.26.mlp.experts.55.down_proj.weight', 'model.layers.26.mlp.experts.55.gate_proj.weight', 'model.layers.26.mlp.experts.55.up_proj.weight', 'model.layers.26.mlp.experts.56.down_proj.weight', 'model.layers.26.mlp.experts.56.gate_proj.weight', 'model.layers.26.mlp.experts.56.up_proj.weight', 'model.layers.26.mlp.experts.57.down_proj.weight', 'model.layers.26.mlp.experts.57.gate_proj.weight', 'model.layers.26.mlp.experts.57.up_proj.weight', 'model.layers.26.mlp.experts.58.down_proj.weight', 'model.layers.26.mlp.experts.58.gate_proj.weight', 'model.layers.26.mlp.experts.58.up_proj.weight', 'model.layers.26.mlp.experts.59.down_proj.weight', 'model.layers.26.mlp.experts.59.gate_proj.weight', 'model.layers.26.mlp.experts.59.up_proj.weight', 'model.layers.26.mlp.experts.6.down_proj.weight', 'model.layers.26.mlp.experts.6.gate_proj.weight', 'model.layers.26.mlp.experts.6.up_proj.weight', 'model.layers.26.mlp.experts.60.down_proj.weight', 'model.layers.26.mlp.experts.60.gate_proj.weight', 'model.layers.26.mlp.experts.60.up_proj.weight', 'model.layers.26.mlp.experts.61.down_proj.weight', 'model.layers.26.mlp.experts.61.gate_proj.weight', 'model.layers.26.mlp.experts.61.up_proj.weight', 'model.layers.26.mlp.experts.62.down_proj.weight', 'model.layers.26.mlp.experts.62.gate_proj.weight', 'model.layers.26.mlp.experts.62.up_proj.weight', 'model.layers.26.mlp.experts.63.down_proj.weight', 'model.layers.26.mlp.experts.63.gate_proj.weight', 'model.layers.26.mlp.experts.63.up_proj.weight', 'model.layers.26.mlp.experts.7.down_proj.weight', 'model.layers.26.mlp.experts.7.gate_proj.weight', 'model.layers.26.mlp.experts.7.up_proj.weight', 'model.layers.26.mlp.experts.8.down_proj.weight', 'model.layers.26.mlp.experts.8.gate_proj.weight', 'model.layers.26.mlp.experts.8.up_proj.weight', 'model.layers.26.mlp.experts.9.down_proj.weight', 'model.layers.26.mlp.experts.9.gate_proj.weight', 'model.layers.26.mlp.experts.9.up_proj.weight', 'model.layers.26.mlp.gate.e_score_correction_bias', 'model.layers.26.mlp.gate.weight', 'model.layers.26.mlp.shared_experts.down_proj.weight', 'model.layers.26.mlp.shared_experts.gate_proj.weight', 'model.layers.26.mlp.shared_experts.up_proj.weight', 'model.layers.26.post_attention_layernorm.weight', 'model.layers.26.self_attn.kv_a_layernorm.weight', 'model.layers.26.self_attn.kv_a_proj_with_mqa.weight', 'model.layers.26.self_attn.kv_b_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.shared_head.head.weight', 'model.layers.26.shared_head.norm.weight']\n",
            "- This IS expected if you are initializing DeepseekV3ForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DeepseekV3ForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Настройка квантизации через BitsAndBytes (4-bit для максимальной экономии памяти)\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "# Загрузка модели с квантизацией\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.generation_config = GenerationConfig.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функции для преобразования промптов для GigaChat3\n",
        "# GigaChat3 использует стандартный chat template, поэтому используем apply_chat_template\n",
        "# Используем глобальную переменную для токенизатора (будет обновлена после создания обертки)\n",
        "_current_tokenizer = tokenizer\n",
        "\n",
        "def messages_to_prompt(messages):\n",
        "    \"\"\"Преобразует сообщения в формат для GigaChat3\"\"\"\n",
        "    # GigaChat3 использует стандартный chat template\n",
        "    formatted_messages = []\n",
        "    for message in messages:\n",
        "        if message.role == 'system':\n",
        "            formatted_messages.append({\"role\": \"system\", \"content\": message.content})\n",
        "        elif message.role == 'user':\n",
        "            formatted_messages.append({\"role\": \"user\", \"content\": message.content})\n",
        "        elif message.role == 'assistant' or message.role == 'bot':\n",
        "            formatted_messages.append({\"role\": \"assistant\", \"content\": message.content})\n",
        "    \n",
        "    # Используем chat template токенизатора\n",
        "    prompt = _current_tokenizer.apply_chat_template(\n",
        "        formatted_messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=False\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "def completion_to_prompt(completion):\n",
        "    \"\"\"Преобразует completion в промпт для GigaChat3\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": completion}\n",
        "    ]\n",
        "    prompt = _current_tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=False\n",
        "    )\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 2,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"temperature\": 0.7,\n",
            "  \"top_p\": 0.3\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Создание LLM обертки для GigaChat3\n",
        "generation_config = GenerationConfig.from_pretrained(model_name)\n",
        "print(generation_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Определяем max_new_tokens с проверкой на None\n",
        "max_new_tokens_value = 1024  # Значение по умолчанию\n",
        "if hasattr(generation_config, 'max_new_tokens') and generation_config.max_new_tokens is not None:\n",
        "    max_new_tokens_value = generation_config.max_new_tokens\n",
        "\n",
        "# Создаем обертку для токенизатора, которая удаляет token_type_ids (не используется в GigaChat3)\n",
        "class TokenizerWrapper:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        # Копируем все атрибуты токенизатора\n",
        "        for attr in dir(tokenizer):\n",
        "            if not attr.startswith('_') and attr != 'encode':\n",
        "                try:\n",
        "                    setattr(self, attr, getattr(tokenizer, attr))\n",
        "                except:\n",
        "                    pass\n",
        "    \n",
        "    def __call__(self, *args, **kwargs):\n",
        "        # Удаляем token_type_ids из результата токенизации\n",
        "        kwargs['return_token_type_ids'] = False\n",
        "        result = self.tokenizer(*args, **kwargs)\n",
        "        if isinstance(result, dict) and 'token_type_ids' in result:\n",
        "            result.pop('token_type_ids')\n",
        "        return result\n",
        "    \n",
        "    def encode(self, *args, **kwargs):\n",
        "        kwargs['return_token_type_ids'] = False\n",
        "        return self.tokenizer.encode(*args, **kwargs)\n",
        "    \n",
        "    def decode(self, *args, **kwargs):\n",
        "        return self.tokenizer.decode(*args, **kwargs)\n",
        "    \n",
        "    def apply_chat_template(self, *args, **kwargs):\n",
        "        return self.tokenizer.apply_chat_template(*args, **kwargs)\n",
        "\n",
        "# Обертываем токенизатор\n",
        "wrapped_tokenizer = TokenizerWrapper(tokenizer)\n",
        "\n",
        "# Обновляем глобальную переменную для функций промптов\n",
        "_current_tokenizer = wrapped_tokenizer\n",
        "\n",
        "# Настраиваем токенизатор, чтобы не передавать token_type_ids\n",
        "tokenizer_kwargs = {'return_token_type_ids': False}\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    model=model,\n",
        "    model_name=model_name,\n",
        "    tokenizer=wrapped_tokenizer,\n",
        "    max_new_tokens=max_new_tokens_value,\n",
        "    model_kwargs={\"quantization_config\": quantization_config},\n",
        "    tokenizer_kwargs=tokenizer_kwargs,\n",
        "    generate_kwargs={\n",
        "        \"temperature\": 0.2,\n",
        "        \"top_p\": 0.9,\n",
        "        \"top_k\": 50,\n",
        "        \"do_sample\": True,\n",
        "        \"repetition_penalty\": 1.1,\n",
        "    },\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    completion_to_prompt=completion_to_prompt,\n",
        "    device_map=\"auto\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-30 17:58:17,563 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
          ]
        }
      ],
      "source": [
        "# Настройка модели встраивания\n",
        "# Отключаем передачу token_type_ids для избежания ошибок\n",
        "embed_model = LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
        "        model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
        "    )\n",
        ")\n",
        "\n",
        "# Настройка глобальных параметров\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.chunk_size = 512\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Функции для возможного вызова моделью\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_deals_statistics():\n",
        "    \"\"\"Получает статистику по сделкам из реестра\"\"\"\n",
        "    try:\n",
        "        with open(deals_registry_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        # Подсчет открытых и закрытых сделок\n",
        "        open_deals = len(re.findall(r'Тип: Открыта', content))\n",
        "        closed_deals = len(re.findall(r'Тип: Закрыта', content))\n",
        "        total_deals = len(re.findall(r'Сделка #', content))\n",
        "        \n",
        "        return {\n",
        "            'open': open_deals,\n",
        "            'closed': closed_deals,\n",
        "            'total': total_deals\n",
        "        }\n",
        "    except FileNotFoundError:\n",
        "        return {'open': 0, 'closed': 0, 'total': 0}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_next_deal_id():\n",
        "    \"\"\"Получает следующий доступный ID сделки\"\"\"\n",
        "    try:\n",
        "        with open(deals_registry_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        # Находим все ID сделок\n",
        "        deal_ids = re.findall(r'Сделка #(\\d+)', content)\n",
        "        if deal_ids:\n",
        "            max_id = max(int(id) for id in deal_ids)\n",
        "            return f\"{max_id + 1:03d}\"\n",
        "        else:\n",
        "            return \"001\"\n",
        "    except FileNotFoundError:\n",
        "        return \"001\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def open_deal(ticker: str, capital_percent: float, entry_price: float, reason: str = \"\"):\n",
        "    \"\"\"\n",
        "    Открывает новую сделку и записывает её в реестр\n",
        "    функция для демонстрации работы (заглушена)\n",
        "    \n",
        "    Args:\n",
        "        ticker: Тикер инструмента (например, SBER, GAZP)\n",
        "        capital_percent: Процент от капитала для сделки\n",
        "        entry_price: Цена входа\n",
        "        reason: Основание для сделки (опционально)\n",
        "    \n",
        "    Returns:\n",
        "        dict: Результат операции с ID сделки\n",
        "    \"\"\"\n",
        "    deal_id = get_next_deal_id()\n",
        "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    \n",
        "    deal_entry = f\"\"\"Сделка #{deal_id}\n",
        "    Тикер: {ticker}\n",
        "    Тип: Открыта\n",
        "    Дата открытия: {current_date}\n",
        "    Цена входа: {entry_price}\n",
        "    Процент от капитала: {capital_percent}%\n",
        "    Основание: {reason if reason else \"Не указано\"}\n",
        "    ---\n",
        "    \"\"\"\n",
        "    \n",
        "    # Записываем в реестр\n",
        "    with open(deals_registry_path, 'a', encoding='utf-8') as f:\n",
        "        f.write(deal_entry)\n",
        "    \n",
        "    return {\n",
        "        \"success\": True,\n",
        "        \"deal_id\": deal_id,\n",
        "        \"message\": f\"Сделка #{deal_id} успешно открыта. Тикер: {ticker}, Цена входа: {entry_price}, Процент от капитала: {capital_percent}%\"\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def close_deal(deal_id: str, exit_price: float, exit_reason: str = \"\"):\n",
        "    \"\"\"\n",
        "    Закрывает существующую сделку в реестре\n",
        "    функция для демонстрации работы (заглушена)\n",
        "    \n",
        "    Args:\n",
        "        deal_id: ID сделки для закрытия (например, \"001\")\n",
        "        exit_price: Цена выхода\n",
        "        exit_reason: Причина закрытия (опционально)\n",
        "    \n",
        "    Returns:\n",
        "        dict: Результат операции с информацией о прибыли/убытке\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(deals_registry_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        # Ищем сделку по ID\n",
        "        pattern = rf'(Сделка #{deal_id}.*?)(?=Сделка #|\\Z)'\n",
        "        match = re.search(pattern, content, re.DOTALL)\n",
        "        \n",
        "        if not match:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": f\"Сделка #{deal_id} не найдена\"\n",
        "            }\n",
        "        \n",
        "        deal_text = match.group(1)\n",
        "        \n",
        "        # Проверяем, что сделка открыта\n",
        "        if 'Тип: Закрыта' in deal_text:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": f\"Сделка #{deal_id} уже закрыта\"\n",
        "            }\n",
        "        \n",
        "        # Извлекаем цену входа\n",
        "        entry_match = re.search(r'Цена входа: ([\\d.]+)', deal_text)\n",
        "        if not entry_match:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": f\"Не удалось найти цену входа для сделки #{deal_id}\"\n",
        "            }\n",
        "        \n",
        "        entry_price = float(entry_match.group(1))\n",
        "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "        \n",
        "        # Вычисляем результат\n",
        "        result_percent = ((exit_price - entry_price) / entry_price) * 100\n",
        "        result_type = \"Прибыль\" if result_percent > 0 else \"Убыток\"\n",
        "        \n",
        "        # Обновляем сделку\n",
        "        updated_deal = deal_text.replace(\n",
        "            'Тип: Открыта',\n",
        "            'Тип: Закрыта'\n",
        "        ).replace(\n",
        "            '---',\n",
        "            f'Дата закрытия: {current_date}\\nЦена выхода: {exit_price}\\nРезультат: {result_type} {abs(result_percent):.2f}%\\nПричина закрытия: {exit_reason if exit_reason else \"Не указана\"}\\n---'\n",
        "        )\n",
        "        \n",
        "        # Заменяем в содержимом\n",
        "        new_content = content.replace(deal_text, updated_deal)\n",
        "        \n",
        "        # Записываем обратно\n",
        "        with open(deals_registry_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(new_content)\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"deal_id\": deal_id,\n",
        "            \"entry_price\": entry_price,\n",
        "            \"exit_price\": exit_price,\n",
        "            \"result_percent\": result_percent,\n",
        "            \"result_type\": result_type,\n",
        "            \"message\": f\"Сделка #{deal_id} закрыта. {result_type}: {abs(result_percent):.2f}%\"\n",
        "        }\n",
        "    \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"message\": f\"Ошибка при закрытии сделки: {str(e)}\"\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reindex_knowledge_base():\n",
        "    \"\"\"Переиндексирует базу знаний, перечитывая все файлы со сделками\"\"\"\n",
        "    global indexKG, storage_context, query_engine, agent, rag_tool, tools\n",
        "    \n",
        "    # Перечитываем документы\n",
        "    documents = SimpleDirectoryReader(source_path).load_data()\n",
        "    \n",
        "    # Создаем новое хранилище\n",
        "    graph_store = SimpleGraphStore()\n",
        "    storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
        "    \n",
        "    # Пересоздаем индекс\n",
        "    indexKG = KnowledgeGraphIndex.from_documents(\n",
        "        documents=documents,\n",
        "        max_triplets_per_chunk=10,\n",
        "        show_progress=True,\n",
        "        include_embeddings=True,\n",
        "        storage_context=storage_context\n",
        "    )\n",
        "    \n",
        "    # Сохраняем индекс\n",
        "    storage_context.persist(persist_dir=storage_path)\n",
        "    \n",
        "    # Пересоздаем query engine\n",
        "    query_engine = indexKG.as_query_engine(include_text=True, verbose=True)\n",
        "    \n",
        "    # Пересоздаем RAG инструмент\n",
        "    rag_tool = QueryEngineTool.from_defaults(\n",
        "        query_engine=query_engine,\n",
        "        description=\"Используй этот инструмент для поиска информации о сделках трейдера в базе знаний.\"\n",
        "    )\n",
        "    \n",
        "    # Обновляем список инструментов\n",
        "    tools = [rag_tool, open_deal_tool, close_deal_tool, get_statistics_tool]\n",
        "    \n",
        "    # Пересоздаем агента\n",
        "    agent = ReActAgent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        verbose=True,\n",
        "        system_prompt=create_system_prompt_with_stats()\n",
        "    )\n",
        "    \n",
        "    return \"База знаний успешно переиндексирована\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Создание базы знаний\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "База знаний представляет из себя реестр сделок, пока только единый реестр для всех трейдеров. Так как я тут пока один, делаю только себя одного, но попутно думаю о многопользовательском режиме, но я все больше склоняюсь к тому, чтобы использовать единый реестр, так как переиндексация может требовать значительного времени, причем, это не настолько сильно зависит от объема самой информации, так как использует одни и те же методы обработки информации для больших файлов и для малых.\n",
        "\n",
        "А в случае использования единого реестра, можно регулярно каждую ночь через крон выполнять переиндексацию, а ретривер настроить таким образом, чтобы он точно знал что искать для конкретного трейдера, так чтобы при общении с единой моделью каждый трейдер получал персонализированный ответ на основе его данных торговли.\n",
        "\n",
        "Вообще, у меня есть мысль для оперативной информации использовать более быстрые способы доставки их в модель. Так я реализовал динамический системный промпт для модели, в которую будет записано текущее количество сделок трейдера, открытые, закрытые и всего. Это решает две проблемы: потенционально снижает уровень галлюцинаций модели при генерации ответов, а также не требует постоянного обращения к базе знаний, чтобы получить какую-либо оперативную информацию (не графовую) по данному трейдеру.\n",
        "\n",
        "Вообще, я выбрал именно графы знаний (Knowledge Graph, KG), так как посчитал, что данный метод идеально подойдет для связанности информации для моего сервиса для трейдеров, например, я делал данную работу под возможность будущего расширения своего другого сервиса по электронному дневнику сделок и уже там у меня возникла мысль объеденить сделки в одну, так у нас сделки обычно исходят из других сделок, например, трейдер совершил первую сделку открытия (лонг или шорт), а затем идут связанные с этой первой сделки другие сделки, такие как усреднения, частичные закрытия и полные закрытия сделок. Это все можно представить в виде графа знаний для модели, надо только наиболее верно структурировать эти данные, чтобы модель, создавая из них граф знаний смогла безошибочно определить связанность информации в едином реестре сделок трейдеров\n",
        "\n",
        "В идеале я представляю себе это так:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        " ```mermaid\n",
        " graph TD\n",
        "     Trader[\"Трейдер\"]\n",
        "     Trader --> Deals[\"Сделки\"]\n",
        "     Deals --> MainDeal1[\"Главная сделка #1 (Открытие позиции)\"]\n",
        "     MainDeal1 --> HelperAvg1[\"Усреднение\"]\n",
        "     MainDeal1 --> HelperExitPart1[\"Частичное закрытие\"]\n",
        "     MainDeal1 --> Closing1[\"Полное закрытие\"]\n",
        "     Deals --> MainDeal2[\"Главная сделка #2 (Открытие позиции)\"]\n",
        "     MainDeal2 --> HelperAvg2[\"Усреднение\"]\n",
        "     MainDeal2 --> Closing2[\"Полное закрытие\"]\n",
        " ```\n",
        "\n",
        " ---\n",
        " В этой схеме:\n",
        " - Каждый трейдер связан со списком своих сделок.\n",
        " - Главная сделка — это сделка открытия позиции (лонг/шорт).\n",
        " - Вспомогательные сделки (узлы второго порядка) — это усреднения, частичные закрытия и прочие операции, связанные с основной.\n",
        " - Каждая главная сделка заканчивается операцией полного закрытия.\n",
        " - Все сделки связаны между собой в рамках единого реестра, что позволяет быстро находить нужную информацию и визуализировать цепочку действий трейдера."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Но пока что же я использую сингл файлы, которые заточены под одного трейдера, это просто как идея для дальнейшего улучшения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Документ 1:\n",
            "\n",
            "Сделка #001\n",
            "Тикер: SBER\n",
            "Тип: Открыта\n",
            "Дата открытия: 2024-01-15\n",
            "Цена входа: 250.50\n",
            "Процент от капитала: 5%\n",
            "Основание: Пробой уровня сопротивления на дневном графике\n",
            "---\n",
            "Сделка #002\n",
            "Тикер: GAZP\n",
            "Тип: Закрыта\n",
            "Дата открытия: 2024-01-10\n",
            "Дата закрытия: 2024-01-20\n",
            "\n",
            "\n",
            "Документ 2:\n",
            "\n",
            "История сделок трейдера\n",
            "\n",
            "Сделка #001\n",
            "Тикер: SBER\n",
            "Тип: Открыта\n",
            "Дата открытия: 2024-01-15\n",
            "Цена входа: 250.50\n",
            "Процент от капитала: 5%\n",
            "Основание: Пробой уровня сопротивления на дневном графике. Объемы выше среднего, формируется восходящий тренд.\n",
            "\n",
            "Сделка #002\n",
            "Т\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Загрузка документов со сделками\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(source_path).load_data()\n",
        "\n",
        "# Проверяем загруженные документы\n",
        "for i, doc in enumerate(documents):\n",
        "    print(f\"Документ {i+1}:\\n\\n{doc.get_content()[:256]}\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создаем графовое хранилище\n",
        "graph_store = SimpleGraphStore()\n",
        "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-30 17:58:21,539 - INFO - Loading all indices.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Загрузка существующего индекса...\n",
            "<llama_index.core.indices.knowledge_graph.base.KnowledgeGraphIndex object at 0x7ae3e8757c80>\n"
          ]
        }
      ],
      "source": [
        "# Построение KnowledgeGraphIndex\n",
        "# Подавляем предупреждение о неиспользуемом параметре token_type_ids\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*token_type_ids.*\")\n",
        "\n",
        "# Импорт функции для загрузки индекса\n",
        "from llama_index.core import load_index_from_storage\n",
        "\n",
        "# путь к индексу\n",
        "storage_path = \"/home/sigma/projects/neuro-assistant-trader-system/data/index/\"\n",
        "\n",
        "# если индекса нет, то создаем\n",
        "# иначе загружаем готовый индекс\n",
        "if not os.path.exists(storage_path) or not os.path.exists(os.path.join(storage_path, \"default__vector_store.json\")):\n",
        "    print(\"Создание нового индекса...\")\n",
        "    indexKG = KnowledgeGraphIndex.from_documents(\n",
        "        documents=documents,\n",
        "        max_triplets_per_chunk=10,\n",
        "        show_progress=True,\n",
        "        include_embeddings=True,\n",
        "        storage_context=storage_context\n",
        "    )\n",
        "    # Сохраняем индекс после создания\n",
        "    storage_context.persist(persist_dir=storage_path)\n",
        "else:\n",
        "    print(\"Загрузка существующего индекса...\")\n",
        "    # Загружаем storage_context из сохраненной директории\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=storage_path)\n",
        "    # Загружаем индекс из storage_context\n",
        "    indexKG = load_index_from_storage(storage_context)\n",
        "    print(indexKG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохранение индекса\n",
        "# storage_context.persist(persist_dir=storage_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Системный промпт с автоматическим добавлением статистики\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В этом системном промпте я и прописал тот самый костыль для возможности вызова функций моделью"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_system_prompt_with_stats():\n",
        "    \"\"\"Создает системный промпт с автоматически добавленной статистикой сделок\"\"\"\n",
        "    stats = get_deals_statistics()\n",
        "    \n",
        "    prompt = f\"\"\"Ты — нейро-помощник для трейдера и ведения электронного дневника трейдера.\n",
        "Твоя задача — помогать трейдеру управлять сделками и отвечать на вопросы по его торговой истории.\n",
        "\n",
        "Текущая статистика сделок:\n",
        "- Всего сделок: {stats['total']}\n",
        "- Открытых сделок: {stats['open']}\n",
        "- Закрытых сделок: {stats['closed']}\n",
        "\n",
        "Ты обращаешься к Источнику, содержащему данные о всех сделках трейдера, и отвечаешь строго на основе Источника.\n",
        "Если информация, которую спрашивает пользователь, недоступна в Источнике или ты не уверен в ответе, скажи честно: 'я не знаю'. Не придумывай ответы и не гадай.\n",
        "\n",
        "КРИТИЧЕСКИ ВАЖНО: Когда пользователь просит что-то сделать или узнать информацию, ТЫ ДОЛЖЕН вызвать соответствующую функцию!\n",
        "\n",
        "Формат вызова функции - выведи ТОЛЬКО JSON без дополнительного текста:\n",
        "{{\"function\": \"имя_функции\", \"arguments\": {{\"параметр1\": \"значение1\", \"параметр2\": \"значение2\"}}}}\n",
        "\n",
        "Доступные функции и когда их использовать:\n",
        "1. get_deals_statistics - ВСЕГДА вызывай, когда пользователь спрашивает \"сколько сделок\", \"статистика\", \"сколько открытых/закрытых\" и т.д.\n",
        "   Формат: {{\"function\": \"get_deals_statistics\", \"arguments\": {{}}}}\n",
        "\n",
        "2. open_deal - ВСЕГДА вызывай, когда пользователь просит открыть сделку, создать сделку, купить акции и т.д.\n",
        "   Формат: {{\"function\": \"open_deal\", \"arguments\": {{\"ticker\": \"SBER\", \"capital_percent\": 5, \"entry_price\": 250.5, \"reason\": \"текст\"}}}}\n",
        "   Пример: \"Открой сделку SBER по цене 258\" -> {{\"function\": \"open_deal\", \"arguments\": {{\"ticker\": \"SBER\", \"capital_percent\": 2, \"entry_price\": 258.0, \"reason\": \"\"}}}}\n",
        "\n",
        "3. close_deal - ВСЕГДА вызывай, когда пользователь просит закрыть сделку.\n",
        "   Формат: {{\"function\": \"close_deal\", \"arguments\": {{\"deal_id\": \"001\", \"exit_price\": 255.0, \"exit_reason\": \"текст\"}}}}\n",
        "\n",
        "4. search_knowledge_base - ВСЕГДА вызывай, когда пользователь спрашивает о сделках, их истории, результатах и т.д.\n",
        "   Формат: {{\"function\": \"search_knowledge_base\", \"arguments\": {{\"query\": \"вопрос пользователя\"}}}}\n",
        "   Пример: \"Какие у меня сделки?\" -> {{\"function\": \"search_knowledge_base\", \"arguments\": {{\"query\": \"Какие у меня сделки?\"}}}}\n",
        "\n",
        "5. reindex_knowledge_base - ВСЕГДА вызывай, когда пользователь просит переиндексировать базу знаний.\n",
        "   Формат: {{\"function\": \"reindex_knowledge_base\", \"arguments\": {{}}}}\n",
        "   Пример: \"Переиндексируй свою базу знаний\" -> {{\"function\": \"reindex_knowledge_base\", \"arguments\": {{}}}}\n",
        "\n",
        "ПРАВИЛА:\n",
        "- НЕ говори \"я не могу\" или \"функционал недоступен\" - ВСЕГДА вызывай функцию, если такие имеются!\n",
        "- Если пользователь спрашивает о сделках - вызывай search_knowledge_base\n",
        "- Если пользователь просит открыть сделку - вызывай open_deal\n",
        "- Если пользователь просит закрыть сделку - вызывай close_deal\n",
        "- Если пользователь спрашивает статистику - вызывай get_deals_statistics\n",
        "- Выводи ТОЛЬКО JSON, без дополнительного текста перед или после!\n",
        "\n",
        "Отвечай четко и по существу, без эмоций. Твоя цель — предоставить точную информацию и помочь трейдеру эффективно управлять сделками.\"\"\"\n",
        "    \n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Интеграция Function Calls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Мои неудачные попытки заставить модель генерировать специальные токены для вызовов функций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.tools import FunctionTool, QueryEngineTool\n",
        "from llama_index.core.agent import ReActAgent\n",
        "\n",
        "# Создаем query engine для RAG\n",
        "query_engine = indexKG.as_query_engine(include_text=True, verbose=True)\n",
        "\n",
        "# Создаем инструмент для работы с базой знаний через RAG\n",
        "rag_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=query_engine,\n",
        "    description=\"Используй этот инструмент для поиска информации о сделках трейдера в базе знаний. Задавай вопросы о конкретных сделках, их истории, результатах и т.д.\"\n",
        ")\n",
        "\n",
        "# Создаем инструменты для function calls\n",
        "open_deal_tool = FunctionTool.from_defaults(\n",
        "    fn=open_deal,\n",
        "    name=\"open_deal\",\n",
        "    description=\"Открывает новую торговую сделку. Параметры: ticker (тикер инструмента, строка), capital_percent (процент от капитала, число), entry_price (цена входа, число), reason (основание для сделки, строка, опционально)\"\n",
        ")\n",
        "\n",
        "close_deal_tool = FunctionTool.from_defaults(\n",
        "    fn=close_deal,\n",
        "    name=\"close_deal\",\n",
        "    description=\"Закрывает существующую торговую сделку. Параметры: deal_id (ID сделки, строка, например '001'), exit_price (цена выхода, число), exit_reason (причина закрытия, строка, опционально)\"\n",
        ")\n",
        "\n",
        "get_statistics_tool = FunctionTool.from_defaults(\n",
        "    fn=get_deals_statistics,\n",
        "    name=\"get_deals_statistics\",\n",
        "    description=\"Получает статистику по всем сделкам: количество открытых, закрытых и всего сделок. Не требует параметров.\"\n",
        ")\n",
        "\n",
        "reindex_knowledge_base_tool = FunctionTool.from_defaults(\n",
        "    fn=reindex_knowledge_base,\n",
        "    name=\"reindex_knowledge_base\",\n",
        "    description=\"Переиндексирует базу знаний. Используй для обновления информации в базе знаний. Не требует параметров.\"\n",
        ")\n",
        "\n",
        "# Список всех инструментов (RAG + function calls)\n",
        "tools = [rag_tool, open_deal_tool, close_deal_tool, get_statistics_tool, reindex_knowledge_base_tool]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Трассировщик запросов Phoenix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "С трассировщиком тоже хапанул проблем, пришлось исправлять на лету, чтобы не затягивать работу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-30 18:02:21,731 - WARNING - Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n",
            "2025-11-30 18:02:21,972 - INFO - Context impl SQLiteImpl.\n",
            "2025-11-30 18:02:21,973 - INFO - Will assume transactional DDL.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
            "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
            "🌍 Phoenix: http://localhost:6006/\n"
          ]
        }
      ],
      "source": [
        "# Настройка трассировки Phoenix\n",
        "import os\n",
        "import warnings\n",
        "import logging\n",
        "import sqlean\n",
        "\n",
        "# Патч sqlean\n",
        "if not hasattr(sqlean, 'extensions'):\n",
        "    from sqlean import extensions\n",
        "    sqlean.extensions = extensions\n",
        "\n",
        "if not hasattr(sqlean, 'connect') or not callable(getattr(sqlean, 'connect', None)):\n",
        "    from sqlean import dbapi2\n",
        "    if hasattr(dbapi2, 'connect'):\n",
        "        sqlean.connect = dbapi2.connect\n",
        "\n",
        "# Импорт Phoenix\n",
        "import phoenix as px\n",
        "from phoenix.server.app import PhoenixMigrationError\n",
        "\n",
        "# Патч percentile для SQLite - улучшенная версия\n",
        "from sqlalchemy import event\n",
        "from sqlalchemy.engine import Engine\n",
        "import sqlalchemy.dialects.sqlite.base as sqlite_base\n",
        "import sqlalchemy.dialects.sqlite.aiosqlite as aiosqlite_module\n",
        "\n",
        "class PercentileAggregate:\n",
        "    \"\"\"Агрегатная функция для вычисления процентилей в SQLite\"\"\"\n",
        "    def __init__(self):\n",
        "        self.values = []\n",
        "        self.p = 0.5\n",
        "    \n",
        "    def step(self, value, p):\n",
        "        if value is not None:\n",
        "            self.values.append(float(value))\n",
        "        if p is not None:\n",
        "            self.p = float(p)\n",
        "    \n",
        "    def finalize(self):\n",
        "        if not self.values:\n",
        "            return None\n",
        "        sorted_vals = sorted(self.values)\n",
        "        index = int(len(sorted_vals) * self.p)\n",
        "        index = min(max(0, index), len(sorted_vals) - 1)\n",
        "        return sorted_vals[index]\n",
        "\n",
        "def add_percentile_to_connection(dbapi_conn):\n",
        "    \"\"\"Добавляет функцию percentile к соединению SQLite\"\"\"\n",
        "    try:\n",
        "        # Пытаемся добавить агрегатную функцию\n",
        "        if hasattr(dbapi_conn, 'create_aggregate'):\n",
        "            dbapi_conn.create_aggregate(\"percentile\", 2, PercentileAggregate)\n",
        "        \n",
        "        # Также добавляем как обычную функцию (на случай, если Phoenix использует её по-другому)\n",
        "        if hasattr(dbapi_conn, 'create_function'):\n",
        "            def percentile_func(value, p):\n",
        "                # Простая реализация для одного значения\n",
        "                if value is None or p is None:\n",
        "                    return None\n",
        "                return float(value) if isinstance(value, (int, float)) else None\n",
        "            dbapi_conn.create_function(\"percentile\", 2, percentile_func)\n",
        "    except Exception as e:\n",
        "        # Игнорируем ошибки при добавлении функции\n",
        "        pass\n",
        "\n",
        "# Патч для синхронных соединений SQLite через SQLAlchemy\n",
        "@event.listens_for(Engine, \"connect\")\n",
        "def receive_connect(dbapi_conn, connection_record):\n",
        "    add_percentile_to_connection(dbapi_conn)\n",
        "\n",
        "# Патч для aiosqlite (асинхронный SQLite, используется Phoenix)\n",
        "try:\n",
        "    import aiosqlite\n",
        "    \n",
        "    # Сохраняем оригинальный класс Connection\n",
        "    original_aiosqlite_connect = aiosqlite.connect\n",
        "    \n",
        "    async def patched_aiosqlite_connect(*args, **kwargs):\n",
        "        \"\"\"Обертка для aiosqlite.connect с добавлением percentile\"\"\"\n",
        "        conn = await original_aiosqlite_connect(*args, **kwargs)\n",
        "        # Добавляем функцию при создании соединения\n",
        "        add_percentile_to_connection(conn)\n",
        "        return conn\n",
        "    \n",
        "    # Патчим функцию connect\n",
        "    aiosqlite.connect = patched_aiosqlite_connect\n",
        "    \n",
        "    # Также патчим on_connect для SQLAlchemy aiosqlite диалекта\n",
        "    if hasattr(aiosqlite_module, 'SQLiteDialect'):\n",
        "        original_on_connect = getattr(aiosqlite_module.SQLiteDialect, 'on_connect', None)\n",
        "        \n",
        "        def patched_on_connect(dbapi_conn, connection_record):\n",
        "            add_percentile_to_connection(dbapi_conn)\n",
        "            if original_on_connect:\n",
        "                result = original_on_connect(dbapi_conn, connection_record)\n",
        "                return result\n",
        "            return None\n",
        "        \n",
        "        aiosqlite_module.SQLiteDialect.on_connect = patched_on_connect\n",
        "        \n",
        "        # Также патчим при каждом создании соединения через Connection\n",
        "        original_connection_init = getattr(aiosqlite.Connection, '__init__', None)\n",
        "        if original_connection_init:\n",
        "            def patched_connection_init(self, *args, **kwargs):\n",
        "                result = original_connection_init(self, *args, **kwargs)\n",
        "                # Добавляем percentile после инициализации\n",
        "                # Используем колбэк для асинхронного добавления\n",
        "                if hasattr(self, '_conn') and self._conn:\n",
        "                    add_percentile_to_connection(self._conn)\n",
        "                return result\n",
        "            \n",
        "            # Применяем патч только если еще не применен\n",
        "            if not hasattr(aiosqlite.Connection, '_percentile_patched'):\n",
        "                aiosqlite.Connection.__init__ = patched_connection_init\n",
        "                aiosqlite.Connection._percentile_patched = True\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Альтернативный патч через SQLAlchemy для aiosqlite\n",
        "if hasattr(aiosqlite_module, 'SQLiteDialect'):\n",
        "    # Патчим метод, который создает соединения\n",
        "    original_get_driver_connection = getattr(aiosqlite_module.SQLiteDialect, '_get_driver_connection', None)\n",
        "    \n",
        "    if original_get_driver_connection:\n",
        "        def patched_get_driver_connection(self, connection):\n",
        "            result = original_get_driver_connection(self, connection)\n",
        "            # Добавляем percentile после получения соединения\n",
        "            if hasattr(result, '_conn'):\n",
        "                add_percentile_to_connection(result._conn)\n",
        "            elif hasattr(result, 'connection'):\n",
        "                add_percentile_to_connection(result.connection)\n",
        "            return result\n",
        "        \n",
        "        aiosqlite_module.SQLiteDialect._get_driver_connection = patched_get_driver_connection\n",
        "\n",
        "# Патч для компиляции SQL запросов с percentile\n",
        "def visit_percentile_impl(self, func, **kw):\n",
        "    \"\"\"Реализация компиляции SQL для функции percentile\"\"\"\n",
        "    col = self.process(func.clauses.clauses[0], **kw)\n",
        "    prob = self.process(func.clauses.clauses[1], **kw)\n",
        "    return f\"percentile({col}, {prob})\"\n",
        "\n",
        "# Добавляем поддержку компиляции percentile в SQLAlchemy\n",
        "if hasattr(sqlite_base, 'SQLiteDialect') and not hasattr(sqlite_base.SQLiteDialect, 'visit_percentile'):\n",
        "    sqlite_base.SQLiteDialect.visit_percentile = visit_percentile_impl\n",
        "\n",
        "if hasattr(aiosqlite_module, 'SQLiteDialect') and not hasattr(aiosqlite_module.SQLiteDialect, 'visit_percentile'):\n",
        "    aiosqlite_module.SQLiteDialect.visit_percentile = visit_percentile_impl\n",
        "\n",
        "# Дополнительный патч через monkey patching для существующих соединений\n",
        "try:\n",
        "    import sqlite3\n",
        "    \n",
        "    original_sqlite3_connect = sqlite3.connect\n",
        "    \n",
        "    def patched_sqlite3_connect(*args, **kwargs):\n",
        "        conn = original_sqlite3_connect(*args, **kwargs)\n",
        "        add_percentile_to_connection(conn)\n",
        "        return conn\n",
        "    \n",
        "    sqlite3.connect = patched_sqlite3_connect\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Настройка логирования\n",
        "warnings.filterwarnings(\"ignore\", message=\".*percentile.*\")\n",
        "logging.getLogger(\"phoenix\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"strawberry\").setLevel(logging.ERROR)\n",
        "\n",
        "# Запуск Phoenix\n",
        "os.environ.setdefault(\"PHOENIX_HOST\", \"127.0.0.1\")\n",
        "os.environ.setdefault(\"PHOENIX_PORT\", \"6006\")\n",
        "\n",
        "try:\n",
        "    session = px.launch_app()\n",
        "    print(\"🌍 Phoenix: http://localhost:6006/\")\n",
        "except PhoenixMigrationError as e:\n",
        "    print(f\"Ошибка миграции: {e}\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-30 18:02:24,757 - WARNING - Attempting to instrument while already instrumented\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Трассировка LlamaIndex настроена. Все запросы к RAG и LLM будут отслеживаться в Phoenix.\n"
          ]
        }
      ],
      "source": [
        "# Настройка инструментации LlamaIndex для трассировки\n",
        "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "\n",
        "# Настраиваем экспорт трассировки в Phoenix\n",
        "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
        "tracer_provider = TracerProvider()\n",
        "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
        "\n",
        "# Инструментируем LlamaIndex для автоматической трассировки всех операций\n",
        "LlamaIndexInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)\n",
        "print(\"✅ Трассировка LlamaIndex настроена. Все запросы к RAG и LLM будут отслеживаться в Phoenix.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Общий вид трассировщика](img/image1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Вид трассировки конкретного запроса](img/image2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Вот как раз с классом ниже у меня и возникли проблемы с вызовом функций, вроде и параметр отдельный имеется, но модель почему-то не вызывает ни в какую\n",
        "\n",
        "Мое предположение таково, что модель просто лишена возможности вызывать функции, она обучена выполнять инструкции, но это совсем не значит, что она может генерировать спец токены для вызова функций. Либо я что-то не так делал, пытаясь разобраться."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создаем ReAct агента с инструментами (RAG + function calls)\n",
        "# Используем конструктор напрямую, так как from_tools может быть недоступен в некоторых версиях\n",
        "agent = ReActAgent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    system_prompt=create_system_prompt_with_stats()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Обработка запросов\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Это громоздкая функция, дорабатывал ее ИИ под все возможные варианты событий, скорее всего, большая часть условий не используется в примерах ниже, но я производил отладку ячеек, но это приводит к частым зависаниям тетрадки и приходится перезапускать полностью среду, чтобы все заработало, поэтому я после нескольких попыток просто забил, в релизе все равно менять модель на ту которая точно умеет вызывать функции (насчет этой я уже не уверен), а там и библиотеку другую использовать, вроде OpenAI, гораздо более приятная и понятная в использовании, особенно, что касается вызовов функций, там я сразу разобрался, а с текущей библиотекой с поиском в графе знаний все сложно.\n",
        "\n",
        "Данная функция и вызывает функцию, читает ответы модели и запросы пользователя и на основе этого взаимодействует с системой"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_query_with_rag_and_functions(query):\n",
        "    \"\"\"Обрабатывает запрос пользователя с использованием RAG и function calls через прямой вызов модели\"\"\"\n",
        "    global model, tokenizer, query_engine\n",
        "    \n",
        "    import json\n",
        "    import re\n",
        "    \n",
        "    # Обновляем системный промпт с актуальной статистикой\n",
        "    system_prompt = create_system_prompt_with_stats()\n",
        "    \n",
        "    # Определяем tools в формате DeepSeek/OpenAI для function calling\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_deals_statistics\",\n",
        "                \"description\": \"Получает статистику по всем сделкам: количество открытых, закрытых и всего сделок. Не требует параметров.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {},\n",
        "                    \"required\": [],\n",
        "                    \"additionalProperties\": False\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"open_deal\",\n",
        "                \"description\": \"Открывает новую торговую сделку. Параметры: ticker (тикер акции, строка), capital_percent (процент от капитала, число), entry_price (цена входа, число), reason (причина открытия, строка, опционально)\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"ticker\": {\"type\": \"string\", \"description\": \"Тикер акции (например, SBER, GAZP)\"},\n",
        "                        \"capital_percent\": {\"type\": \"number\", \"description\": \"Процент от капитала для сделки\", \"minimum\": 0, \"maximum\": 100},\n",
        "                        \"entry_price\": {\"type\": \"number\", \"description\": \"Цена входа в сделку\", \"minimum\": 0},\n",
        "                        \"reason\": {\"type\": \"string\", \"description\": \"Причина открытия сделки (опционально)\"}\n",
        "                    },\n",
        "                    \"required\": [\"ticker\", \"capital_percent\", \"entry_price\"],\n",
        "                    \"additionalProperties\": False\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"close_deal\",\n",
        "                \"description\": \"Закрывает существующую торговую сделку. Параметры: deal_id (ID сделки, строка, например '001'), exit_price (цена выхода, число), exit_reason (причина закрытия, строка, опционально)\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"deal_id\": {\"type\": \"string\", \"description\": \"ID сделки (например, '001', '002')\"},\n",
        "                        \"exit_price\": {\"type\": \"number\", \"description\": \"Цена выхода из сделки\", \"minimum\": 0},\n",
        "                        \"exit_reason\": {\"type\": \"string\", \"description\": \"Причина закрытия сделки (опционально)\"}\n",
        "                    },\n",
        "                    \"required\": [\"deal_id\", \"exit_price\"],\n",
        "                    \"additionalProperties\": False\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"search_knowledge_base\",\n",
        "                \"description\": \"Ищет информацию о сделках трейдера в базе знаний. Используй для вопросов о конкретных сделках, их истории, результатах и т.д.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"query\": {\"type\": \"string\", \"description\": \"Вопрос для поиска в базе знаний\"}\n",
        "                    },\n",
        "                    \"required\": [\"query\"],\n",
        "                    \"additionalProperties\": False\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"reindex_knowledge_base\",\n",
        "                \"description\": \"Переиндексирует базу знаний. Используй для обновления информации в базе знаний.\",\n",
        "                \"parameters\": {}\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    # Формируем сообщения для модели с few-shot примерами\n",
        "    # Добавляем примеры вызова функций в системный промпт\n",
        "    few_shot_examples = \"\"\"\n",
        "\n",
        "Примеры правильного вызова функций:\n",
        "\n",
        "Пользователь: \"Сколько у меня сделок?\"\n",
        "Ты должен ответить ТОЛЬКО JSON:\n",
        "{\"function\": \"get_deals_statistics\", \"arguments\": {}}\n",
        "\n",
        "Пользователь: \"Какие у меня сделки?\"\n",
        "Ты должен ответить ТОЛЬКО JSON:\n",
        "{\"function\": \"search_knowledge_base\", \"arguments\": {\"query\": \"Какие у меня сделки?\"}}\n",
        "\n",
        "Пользователь: \"Открой сделку по тикеру SBER, цена входа 258.00, процент от капитала 2%\"\n",
        "Ты должен ответить ТОЛЬКО JSON:\n",
        "{\"function\": \"open_deal\", \"arguments\": {\"ticker\": \"SBER\", \"capital_percent\": 2, \"entry_price\": 258.0, \"reason\": \"\"}}\n",
        "\n",
        "Пользователь: \"Закрой сделку 001 по цене 255\"\n",
        "Ты должен ответить ТОЛЬКО JSON:\n",
        "{\"function\": \"close_deal\", \"arguments\": {\"deal_id\": \"001\", \"exit_price\": 255.0, \"exit_reason\": \"\"}}\n",
        "\n",
        "ВАЖНО: Отвечай ТОЛЬКО JSON, без дополнительного текста!\n",
        "\"\"\"\n",
        "    \n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt + few_shot_examples},\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ]\n",
        "    \n",
        "    max_iterations = 5  # Максимальное количество итераций для function calling\n",
        "    iteration = 0\n",
        "    \n",
        "    while iteration < max_iterations:\n",
        "        iteration += 1\n",
        "        \n",
        "        # Используем сообщения напрямую (описание tools уже в системном промпте)\n",
        "        messages_with_tools = messages\n",
        "        \n",
        "        # Вызываем модель\n",
        "        try:\n",
        "            # Используем chat template для форматирования сообщений\n",
        "            prompt = tokenizer.apply_chat_template(\n",
        "                messages_with_tools,\n",
        "                add_generation_prompt=True,\n",
        "                tokenize=False\n",
        "            )\n",
        "            \n",
        "            # Токенизируем и генерируем ответ\n",
        "            # Убеждаемся, что token_type_ids не передается\n",
        "            inputs = tokenizer(prompt, return_tensors=\"pt\", return_token_type_ids=False).to(model.device)\n",
        "            # Удаляем token_type_ids из inputs, если он там есть\n",
        "            if 'token_type_ids' in inputs:\n",
        "                inputs.pop('token_type_ids')\n",
        "            \n",
        "            outputs = model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs.get('attention_mask', None),\n",
        "                max_new_tokens=512,\n",
        "                temperature=0.2,\n",
        "                top_p=0.9,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "            \n",
        "            # Декодируем ответ\n",
        "            response_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "            \n",
        "            # Отладочный вывод (можно убрать позже)\n",
        "            if iteration == 1:\n",
        "                print(f\"[DEBUG] Ответ модели (итерация {iteration}): {response_text[:500]}\")\n",
        "            \n",
        "            # Парсим ответ модели на предмет вызова функции\n",
        "            # Модель должна сама решить, вызывать функцию или нет\n",
        "            # Ищем структурированный JSON в формате: {\"function\": \"имя\", \"arguments\": {...}}\n",
        "            function_called = None\n",
        "            function_args = {}\n",
        "            \n",
        "            # Сначала пытаемся найти JSON блок, который начинается с {\"function\"\n",
        "            # Ищем от начала строки или после любого текста\n",
        "            json_start_pattern = r'\\{[^{}]*\"function\"[^{}]*'\n",
        "            \n",
        "            # Находим начало JSON блока\n",
        "            start_match = re.search(json_start_pattern, response_text)\n",
        "            if start_match:\n",
        "                start_pos = start_match.start()\n",
        "                # Пытаемся найти полный JSON блок, начиная с этой позиции\n",
        "                # Используем простой алгоритм подсчета скобок\n",
        "                brace_count = 0\n",
        "                json_str = \"\"\n",
        "                in_string = False\n",
        "                escape_next = False\n",
        "                \n",
        "                for i, char in enumerate(response_text[start_pos:], start_pos):\n",
        "                    json_str += char\n",
        "                    if escape_next:\n",
        "                        escape_next = False\n",
        "                        continue\n",
        "                    if char == '\\\\':\n",
        "                        escape_next = True\n",
        "                        continue\n",
        "                    if char == '\"':\n",
        "                        in_string = not in_string\n",
        "                        continue\n",
        "                    if not in_string:\n",
        "                        if char == '{':\n",
        "                            brace_count += 1\n",
        "                        elif char == '}':\n",
        "                            brace_count -= 1\n",
        "                            if brace_count == 0:\n",
        "                                # Нашли полный JSON блок\n",
        "                                try:\n",
        "                                    parsed = json.loads(json_str)\n",
        "                                    if isinstance(parsed, dict) and \"function\" in parsed:\n",
        "                                        func_name = parsed.get(\"function\")\n",
        "                                        valid_funcs = [tool[\"function\"][\"name\"] for tool in tools]\n",
        "                                        if func_name in valid_funcs:\n",
        "                                            function_called = func_name\n",
        "                                            function_args = parsed.get(\"arguments\", {})\n",
        "                                            break\n",
        "                                except:\n",
        "                                    pass\n",
        "                                break\n",
        "            \n",
        "            # Если не нашли через подсчет скобок, пробуем более простой подход\n",
        "            if not function_called:\n",
        "                # Ищем JSON блок с помощью регулярного выражения (более гибкий)\n",
        "                json_pattern = r'\\{\\s*\"function\"\\s*:\\s*\"([^\"]+)\"\\s*,\\s*\"arguments\"\\s*:\\s*(\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\})\\s*\\}'\n",
        "                json_match = re.search(json_pattern, response_text, re.DOTALL)\n",
        "                if json_match:\n",
        "                    try:\n",
        "                        func_name = json_match.group(1)\n",
        "                        args_str = json_match.group(2)\n",
        "                        valid_funcs = [tool[\"function\"][\"name\"] for tool in tools]\n",
        "                        if func_name in valid_funcs:\n",
        "                            function_called = func_name\n",
        "                            try:\n",
        "                                function_args = json.loads(args_str)\n",
        "                            except:\n",
        "                                function_args = {}\n",
        "                    except:\n",
        "                        pass\n",
        "            \n",
        "            # Если все еще не нашли, пробуем найти любой валидный JSON в ответе\n",
        "            if not function_called:\n",
        "                # Ищем все возможные JSON блоки\n",
        "                json_candidates = re.findall(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', response_text)\n",
        "                for candidate in json_candidates:\n",
        "                    try:\n",
        "                        parsed = json.loads(candidate)\n",
        "                        if isinstance(parsed, dict) and \"function\" in parsed:\n",
        "                            func_name = parsed.get(\"function\")\n",
        "                            valid_funcs = [tool[\"function\"][\"name\"] for tool in tools]\n",
        "                            if func_name in valid_funcs:\n",
        "                                function_called = func_name\n",
        "                                function_args = parsed.get(\"arguments\", {})\n",
        "                                break\n",
        "                    except:\n",
        "                        continue\n",
        "            \n",
        "            # Отладочный вывод\n",
        "            if function_called:\n",
        "                print(f\"[DEBUG] Найдена функция: {function_called}, аргументы: {function_args}\")\n",
        "            else:\n",
        "                print(f\"[DEBUG] Функция не найдена в ответе модели\")\n",
        "            \n",
        "            # Если функция вызвана, выполняем её\n",
        "            if function_called:\n",
        "                if function_called == \"get_deals_statistics\":\n",
        "                    result = get_deals_statistics()\n",
        "                    result_text = f\"Статистика: всего {result['total']} сделок, открытых {result['open']}, закрытых {result['closed']}\"\n",
        "                elif function_called == \"open_deal\":\n",
        "                    result = open_deal(\n",
        "                        function_args.get(\"ticker\"),\n",
        "                        function_args.get(\"capital_percent\"),\n",
        "                        function_args.get(\"entry_price\"),\n",
        "                        function_args.get(\"reason\", \"\")\n",
        "                    )\n",
        "                    result_text = result.get('message', str(result))\n",
        "                elif function_called == \"close_deal\":\n",
        "                    result = close_deal(\n",
        "                        function_args.get(\"deal_id\"),\n",
        "                        function_args.get(\"exit_price\"),\n",
        "                        function_args.get(\"exit_reason\", \"\")\n",
        "                    )\n",
        "                    result_text = result.get('message', str(result))\n",
        "                elif function_called == \"search_knowledge_base\":\n",
        "                    rag_query = function_args.get(\"query\", query)\n",
        "                    rag_response = query_engine.query(rag_query)\n",
        "                    result_text = rag_response.response\n",
        "                elif function_called == \"reindex_knowledge_base\":\n",
        "                    reindex_knowledge_base()\n",
        "                    result_text = \"База знаний переиндексирована\"\n",
        "                else:\n",
        "                    result_text = \"Неизвестная функция\"\n",
        "                \n",
        "                # Добавляем результат в историю сообщений\n",
        "                messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
        "                messages.append({\"role\": \"user\", \"content\": f\"Результат выполнения функции {function_called}: {result_text}. Продолжи ответ пользователю.\"})\n",
        "                \n",
        "                # Продолжаем цикл для получения финального ответа\n",
        "                continue\n",
        "            else:\n",
        "                # Нет вызова функции - возвращаем ответ модели\n",
        "                # Модель сама решила, что функция не нужна\n",
        "                return response_text.strip()\n",
        "        \n",
        "        except Exception as e:\n",
        "            return f\"Ошибка при обработке запроса: {e}\"\n",
        "    \n",
        "    # Если превышено количество итераций\n",
        "    return \"Превышено максимальное количество итераций. Попробуйте переформулировать запрос.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Модерация через OpenAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Модерация опциональная и использует эндпоинт API OpenAI, конечно, такой варинат не подойдет для корпоративной среды, но добавил это сюда чисто для примера, также можно поднять свой эндпоинт формата OpenAI и просто при инициализации экземпляра класса поменять в атрибуте URL-адреса на свой сервер и все будет работать с вашим собственным сервером.\n",
        "\n",
        "Просто формат тетрадки не подходит для демонстрации работ систем на основе микросервисов, можно конечно, через сабпроцессы запускать микросервисы, но это походит больше на извращения, нежели на здравое решение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    # Try to read token from .env file in current or parent directories\n",
        "    from dotenv import load_dotenv, find_dotenv\n",
        "    dotenv_path = find_dotenv()\n",
        "    if dotenv_path:\n",
        "        load_dotenv(dotenv_path)\n",
        "        OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not OPENAI_API_KEY:\n",
        "        import getpass\n",
        "        OPENAI_API_KEY = getpass.getpass(\"Введите OpenAI API Key:\")\n",
        "        os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "    else:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "else:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# Инициализация клиента OpenAI (для новой версии API)\n",
        "try:\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    USE_NEW_API = True\n",
        "except:\n",
        "    # Fallback на старую версию\n",
        "    import openai\n",
        "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    USE_NEW_API = False\n",
        "\n",
        "# Список категорий, которые надо заблокировать\n",
        "BLOCKED_CATEGORIES = [\"hate\", \"violence\", \"self-harm\", \"sexual\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def moderate_request_gpt35(prompt):\n",
        "    \"\"\"Модерация запроса через OpenAI\"\"\"\n",
        "    try:\n",
        "        if USE_NEW_API:\n",
        "            response = client.moderations.create(input=prompt)\n",
        "            results = response.results[0]\n",
        "        else:\n",
        "            response = openai.Moderation.create(input=prompt)\n",
        "            results = response[\"results\"][0]\n",
        "\n",
        "        # Проверяем только те категории, которые в списке BLOCKED_CATEGORIES\n",
        "        if USE_NEW_API:\n",
        "            categories = results.categories\n",
        "            flagged_categories = [\n",
        "                category for category in BLOCKED_CATEGORIES\n",
        "                if getattr(categories, category, False)\n",
        "            ]\n",
        "        else:\n",
        "            flagged_categories = [\n",
        "                category for category, flagged in results[\"categories\"].items()\n",
        "                if flagged and category in BLOCKED_CATEGORIES\n",
        "            ]\n",
        "\n",
        "        if flagged_categories:\n",
        "            return False, flagged_categories\n",
        "        return True, None\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка модерации: {e}\")\n",
        "        # В случае ошибки разрешаем запрос\n",
        "        return True, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_request(query, moderate=False):\n",
        "    \"\"\"Обрабатывает запрос с опциональной модерацией и функционалом RAG + function calls\"\"\"\n",
        "    # Модерация запроса\n",
        "    if moderate:\n",
        "        allowed, categories = moderate_request_gpt35(query)\n",
        "        if not allowed:\n",
        "            return f\"Запрос заблокирован модерацией из-за содержания в категориях: {categories}\"\n",
        "    \n",
        "    # Обработка запроса\n",
        "    response = process_query_with_rag_and_functions(query)\n",
        "    \n",
        "    if moderate:\n",
        "        # Модерация ответа\n",
        "        allowed_response, response_categories = moderate_request_gpt35(str(response))\n",
        "        if not allowed_response:\n",
        "            return \"Ответ отклонён модерацией\"\n",
        "    \n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Примеры использования\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Ответ модели (итерация 1): {\"function\": \"search_knowledge_base\", \"arguments\": {\"query\": \"Какие у меня сделки?\"}}\n",
            "[DEBUG] Найдена функция: search_knowledge_base, аргументы: {'query': 'Какие у меня сделки?'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-30 01:35:52,720 - INFO - > Querying with idx: 64fd15ea-892a-4c47-99a7-5242ff54e094: История сделок трейдера\n",
            "\n",
            "Сделка #001\n",
            "Тикер: SBER\n",
            "Тип: Открыта\n",
            "Дата открытия: ...\n",
            "2025-11-30 01:35:52,720 - INFO - > Querying with idx: 07ae3af7-22b6-4eec-8f5e-4e28ac01cdd4: Результат: Прибыль +4.2%\n",
            "Причина закрытия: Достигнут целевой уровень прибыли....\n",
            "2025-11-30 01:35:52,721 - INFO - > Querying with idx: 1a04e31c-d81d-4af0-ae15-e13b71784e61: Сделка #001\n",
            "Тикер: SBER\n",
            "Тип: Открыта\n",
            "Дата открытия: 2024-01-15\n",
            "Цена входа: 25...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;32mExtracted keywords: ['у', \"у меня'\", 'какие', \"'сделки\", 'меня']\n",
            "\u001b[0m\u001b[1;3;34mKG context:\n",
            "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
            "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
            "('Deals', 'Is', 'Example_deals')\n",
            "('Price entry', 'Is', '180.25')\n",
            "\u001b[0m[DEBUG] Функция не найдена в ответе модели\n",
            "Ответ:\n",
            "В вашем контексте также есть две открытые сделки:\n",
            "\n",
            "1. Сделка №001 с тикером SBER — открыта, дата открытия 2024-01-15, цена входа 250.50, процент от капитала 5%, основание пробой уровня сопротивления на дневном графике.\n",
            "2. Сделка №003 с тикер YNDX — закрытая, дата открытия 2024-01-05, дата закрытия 2024-01-12, цена вход 3200.00, результат убыток -3.1%.\n"
          ]
        }
      ],
      "source": [
        "# Пример 1: Получение статистики\n",
        "query = \"Какие там у меня сделки?\"\n",
        "response = process_request(query)\n",
        "print(\"Ответ:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Ответ модели (итерация 1): {\"function\": \"open_deal\", \"arguments\": {\"ticker\": \"SBER\", \"capital_percent\": 2, \"entry_price\": 258.0, \"reason\": \"пробой сопротивления\"}}\n",
            "[DEBUG] Найдена функция: open_deal, аргументы: {'ticker': 'SBER', 'capital_percent': 2, 'entry_price': 258.0, 'reason': 'пробой сопротивления'}\n",
            "[DEBUG] Функция не найдена в ответе модели\n",
            "Ответ:\n",
            "Отлично! У тебя теперь есть новая сделка с тикером SBER по цене входа 258.0, открытая на 2% от капитала. Следующий шаг будет зависеть от твоей стратегии управления рисками и целей торговли.\n"
          ]
        }
      ],
      "source": [
        "# Пример 2: Открытие новой сделки\n",
        "query = \"Открой сделку по тикеру SBER, цена входа 258.00, процент от капитала 2%, основание: пробой сопротивления\"\n",
        "response = process_request(query)\n",
        "print(\"Ответ:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Ответ модели (итерация 1): {\"function\": \"search_knowledge_base\", \"arguments\": {\"query\": \"мои закрытые сделки\"}}\n",
            "[DEBUG] Найдена функция: search_knowledge_base, аргументы: {'query': 'мои закрытые сделки'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-29 23:47:27,771 - INFO - > Querying with idx: 1a04e31c-d81d-4af0-ae15-e13b71784e61: Сделка #001\n",
            "Тикер: SBER\n",
            "Тип: Открыта\n",
            "Дата открытия: 2024-01-15\n",
            "Цена входа: 25...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;32mExtracted keywords: ['мои', 'сделки', 'закрытые']\n",
            "\u001b[0m\u001b[1;3;34mKG context:\n",
            "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
            "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
            "('Deal #003', 'Is', 'Closed deal')\n",
            "('Deal #002', 'Is', 'Closed deal')\n",
            "\u001b[0m[DEBUG] Функция не найдена в ответе модели\n",
            "Ответ:\n",
            "Ваши закрытые сделки: #002 и #003.\n"
          ]
        }
      ],
      "source": [
        "# Пример 3: Вопрос по истории сделок\n",
        "query = \"Расскажи о моих закрытых сделках\"\n",
        "response = process_request(query)\n",
        "print(\"Ответ:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Ответ модели (итерация 1): {\"function\": \"close_deal\", \"arguments\": {\"deal_id\": \"005\", \"exit_price\": 259.3, \"exit_reason\": \"достигнут тейк-профит\"}}\n",
            "[DEBUG] Найдена функция: close_deal, аргументы: {'deal_id': '005', 'exit_price': 259.3, 'exit_reason': 'достигнут тейк-профит'}\n",
            "[DEBUG] Функция не найдена в ответе модели\n",
            "Ответ:\n",
            "Отлично! Сделка #005 успешно закрыта с прибылью в размере 0.50%. Это был хороший результат. Какую стратегию вы планируете применить дальше?\n"
          ]
        }
      ],
      "source": [
        "# Пример 4: Закрытие сделки\n",
        "query = \"Закрой сделку #005, цена выхода 259.30, причина: достигнут тейк-профит\"\n",
        "response = process_request(query)\n",
        "print(\"Ответ:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Ответ модели (итерация 1): {\"function\": \"reindex_knowledge_base\", \"arguments\": {}}\n",
            "[DEBUG] Найдена функция: reindex_knowledge_base, аргументы: {}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5fc7ebc210f422bba28b84516e4dc63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing nodes:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f9d85635a614f20a7fe6b72f57e915b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing nodes:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "924741c0fa5e4b8a99b07d8c79024d7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6778912beb841bcb85bb1c6a74761ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00462973dc79441d813c0bcea1273297",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6de82e2f899b4e1da69c4af735fe8559",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c21cabb096847489fd20fb690d8ec17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Функция не найдена в ответе модели\n",
            "Ответ:\n",
            "{\"status\": \"success\", \"message\": \"База знаний успешно переиндексирована.\"}\n"
          ]
        }
      ],
      "source": [
        "query = \"Переиндексируй свою базу знаний\"\n",
        "response = process_request(query)\n",
        "print(\"Ответ:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Борьба с галлюцинациями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В данной системе вероятность галлюцинаций относительно низка по нескольким причинам:\n",
        "\n",
        "1. **Ограниченный функционал**: Модель работает в узкой предметной области (управление сделками трейдера) с четко определенным набором функций.\n",
        "\n",
        "2. **Простая структура базы знаний**: База знаний содержит структурированную информацию о сделках в текстовом формате, что упрощает извлечение и проверку фактов.\n",
        "\n",
        "3. **Явные инструкции в системном промпте**: Модель явно инструктируется отвечать \"я не знаю\", если информация отсутствует в источнике.\n",
        "\n",
        "4. **Дополнительная мера - ресортировка контента**: В качестве дополнительной меры можно использовать `LongContextReorder` для улучшения качества извлечения релевантной информации из базы знаний, снижая вероятность того, что модель будет опираться на нерелевантные фрагменты контекста. Однако основная работа системы выполняется без ресортировки.\n",
        "\n",
        "**Слабые стороны в борьбе с галлюцинациями**\n",
        "\n",
        "Несмотря на принятые меры, система имеет следующие ограничения:\n",
        "\n",
        "1. **Отсутствие явной верификации фактов**: Система не проверяет факты из базы знаний перед их использованием в ответе.\n",
        "\n",
        "2. **Ограниченная обработка противоречий**: Если в базе знаний есть противоречивая информация, система может выбрать случайный вариант без явного указания на противоречие.\n",
        "\n",
        "3. **Зависимость от качества индексации**: Качество ответов напрямую зависит от того, насколько хорошо информация извлечена и проиндексирована в KnowledgeGraphIndex.\n",
        "\n",
        "4. **Отсутствие метаданных о достоверности**: Система не предоставляет информацию о том, насколько уверена модель в своем ответе или насколько релевантны найденные фрагменты.\n",
        "\n",
        "5. **Потенциальные проблемы с интерполяцией**: Модель может пытаться \"дополнить\" информацию из базы знаний своими предположениями, особенно при неполных данных.\n",
        "\n",
        "Для дальнейшего улучшения можно рассмотреть:\n",
        "- Добавление системы оценки достоверности ответов\n",
        "- Внедрение явной верификации фактов через дополнительные запросы к базе знаний\n",
        "- Использование ансамбля моделей для проверки согласованности ответов\n",
        "- Добавление метаданных о релевантности найденных фрагментов в ответы модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-30 18:18:39,781 - INFO - > Querying with idx: 29dbb21d-90ac-43c3-a314-7adad3cd079d: 00\n",
            "Цена выхода: 3100.00\n",
            "Процент от капитала: 4%\n",
            "Основание: Пробой нисходящего...\n",
            "2025-11-30 18:18:39,782 - INFO - > Querying with idx: 388b3f3f-712c-4f72-b9e5-0dcc0b0aa020: История сделок трейдера\n",
            "\n",
            "Сделка #001\n",
            "Тикер: SBER\n",
            "Тип: Открыта\n",
            "Дата открытия: ...\n",
            "2025-11-30 18:18:39,782 - INFO - > Querying with idx: 4ccfd7b3-6699-4ca0-a047-5b821ed4f964: Результат: Прибыль +4.2%\n",
            "Причина закрытия: Достигнут целевой уровень прибыли....\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;32mExtracted keywords: ['deals', 'open deals', 'SBER', 'open', 'ticker']\n",
            "\u001b[0m\u001b[1;3;34mKG context:\n",
            "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
            "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
            "('Сделка #005', 'Тикer', 'Sber')\n",
            "('Сделка #004', 'Тикер', 'Sber')\n",
            "\u001b[0mОтвет БЕЗ ресортировки контента:\n",
            "У вас есть две открытые сделки с тикером SBER:\n",
            "\n",
            "1. Сделка №001 — открыта, дата открытия 2024-01-15, цена входа 250.50, процент от капитала 5%.\n",
            "2. Сделка №005 — открыта, дата открытия 2024-01-22, цена входа 0.035, процент от капитала 2%.\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-30 18:19:22,241 - INFO - > Querying with idx: 29dbb21d-90ac-43c3-a314-7adad3cd079d: 00\n",
            "Цена выхода: 3100.00\n",
            "Процент от капитала: 4%\n",
            "Основание: Пробой нисходящего...\n",
            "2025-11-30 18:19:22,241 - INFO - > Querying with idx: 4ccfd7b3-6699-4ca0-a047-5b821ed4f964: Результат: Прибыль +4.2%\n",
            "Причина закрытия: Достигнут целевой уровень прибыли....\n",
            "2025-11-30 18:19:22,241 - INFO - > Querying with idx: 388b3f3f-712c-4f72-b9e5-0dcc0b0aa020: История сделок трейдера\n",
            "\n",
            "Сделка #001\n",
            "Тикер: SBER\n",
            "Тип: Открыта\n",
            "Дата открытия: ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;32mExtracted keywords: ['deals', 'open deals', 'SBER', 'open', 'ticker']\n",
            "\u001b[0m\u001b[1;3;34mKG context:\n",
            "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
            "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
            "('Сделка #005', 'Цена входа', '258.0')\n",
            "('Сделка #005', 'Цена входа', '0.035')\n",
            "('Сделка #004', 'Цена входа', '260.0')\n",
            "('Сделка #004', 'Тип', 'Открыта')\n",
            "('Сделка #005', 'Тип', 'Открыта')\n",
            "('Сделка #005', 'Тикer', 'Sber')\n",
            "('Сделка #004', 'Тикер', 'Sber')\n",
            "('Сделка #005', 'Тикер', 'Vtbr')\n",
            "('Price entry', 'Is', '3200.00')\n",
            "('Price entry', 'Is', '180.25')\n",
            "\u001b[0mОтвет С ресортировкой контента:\n",
            "У вас есть две открытые сделки по тикеру SBER:\n",
            "\n",
            "1. Сделка №004 — открыта с ценой входа 260.0\n",
            "2. Сделка №005 — открыта с ценой входа 258.0\n",
            "\n",
            "======================================================================\n",
            "Ресортировка контента как дополнительная мера помогает:\n",
            "- Правильно расставить приоритеты между релевантными фрагментами\n",
            "- Снизить влияние нерелевантных фрагментов на ответ\n",
            "- Улучшить качество ответов при работе с длинным контекстом\n",
            "- Снизить вероятность галлюцинаций за счет лучшей структуризации контекста\n"
          ]
        }
      ],
      "source": [
        "# Пример использования ресортировки контента как дополнительной меры борьбы с галлюцинациями\n",
        "# Создаем отдельный query engine с ресортировкой для сравнения\n",
        "\n",
        "reorder = LongContextReorder()\n",
        "\n",
        "# Query engine с ресортировкой контента (дополнительная мера)\n",
        "query_engine_with_reorder = indexKG.as_query_engine(\n",
        "    include_text=True,\n",
        "    verbose=True,\n",
        "    similarity_top_k=10,\n",
        "    node_postprocessors=[reorder]\n",
        ")\n",
        "\n",
        "query = \"Какие у меня открытые сделки по тикеру SBER?\"\n",
        "\n",
        "# Сравнение: ответ без ресортировки (основной query_engine)\n",
        "response_standard = query_engine.query(query)\n",
        "print(\"Ответ БЕЗ ресортировки контента:\")\n",
        "print(response_standard.response)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Ответ с ресортировкой (дополнительная мера)\n",
        "response_reordered = query_engine_with_reorder.query(query)\n",
        "print(\"Ответ С ресортировкой контента:\")\n",
        "print(response_reordered.response)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Ресортировка контента как дополнительная мера помогает:\")\n",
        "print(\"- Правильно расставить приоритеты между релевантными фрагментами\")\n",
        "print(\"- Снизить влияние нерелевантных фрагментов на ответ\")\n",
        "print(\"- Улучшить качество ответов при работе с длинным контекстом\")\n",
        "print(\"- Снизить вероятность галлюцинаций за счет лучшей структуризации контекста\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Заключение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В данном блокноте реализован трейдерский нейро-помощник, объединяющий:\n",
        "1. RAG-систему на основе LlamaIndex с KnowledgeGraphIndex для работы с базой знаний о сделках\n",
        "2. Модель GigaChat3 (российская контурная LLM) с квантизацией для эффективной работы\n",
        "3. Function calling для выполнения действий (открытие/закрытие сделок)\n",
        "4. Автоматическое добавление статистики сделок в контекст\n",
        "5. Модерацию через OpenAI API для безопасности\n",
        "6. Возможность переиндексирования базы знаний\n",
        "7. Трассировку запросов и ответов\n",
        "8. Борьбу с возможными галлюцинациями и выявление слабых сторон\n",
        "\n",
        "Система готова к использованию в электронном дневнике трейдера и может быть расширена дополнительными функциями по мере необходимости.\n",
        "\n",
        "Конечно, стоит сказать, что данная работа это больше демонстрация и определение вектора развития конкретного сервиса, данная работа была выполнена с целью поиска наиболее оптимального решения задачи по разработке ассистента для трейдера и системы трейдера, помощи в осуществлении торговых операция и принятий решения, а также возможность автоматической или полу-автоматической торговли.\n",
        "\n",
        "Само собой многое еще предстоит сделать, но это уже совсем другая история..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
